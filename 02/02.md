# Getting started

## Dependencies

In this tutorial, we'll be using:

- Docker Engine (v20.10)
- Kubernetes (v1.21)
- kind (v0.11)
- kubectl (v1.21)
- Python (v3.9)
- A GitHub/GitLab/BitBucket/Custom Git repository provider account (your choice)

Let's start by installing [kind](https://kind.sigs.k8s.io/). kind requires that the Docker daemon is running on your local machine, so please [install](https://www.docker.com/get-started) it if you don't already have it before moving on.
*ADD WHAT TO DO IF YOU RECEIVE AN INSTALLATION ERROR: EG; ERROR: failed to create cluster: node(s) already exist for a cluster with the name "kind"

Follow the instructions [here](https://kind.sigs.k8s.io/docs/user/quick-start/#installation) to install kind for your specific operating system.

## Kubernetes Cluster

Create the cluster by running:

```bash
$ kind create cluster --name cluster1
```

This will take a few minutes the first time as Docker images as large as 1.33GB are going to be downloaded.

You should see something similar to:

```bash
Creating cluster "cluster1" ...
 ✓ Ensuring node image (kindest/node:v1.21.1) 🖼
 ✓ Preparing nodes 📦
 ✓ Writing configuration 📜
 ✓ Starting control-plane 🕹️
 ✓ Installing CNI 🔌
 ✓ Installing StorageClass 💾
Set kubectl context to "kind-cluster1"
You can now use your cluster with:

kubectl cluster-info --context kind-cluster1

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community 🙂
```

To see if the cluster is running, we can use [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/). You'll want to download and install the same version of kubectl as your Kubernetes cluster.

First, to get the Kubernetes version, run the following command:

```bash
$ docker ps --filter "name=cluster1"
```

You should see something similar to:

```bash
CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS                       NAMES
ae6ff5184cd6   kindest/node:v1.21.1   "/usr/local/bin/entr…"   17 minutes ago   Up 17 minutes   127.0.0.1:61107->6443/tcp   cluster1-control-plane
```
*ADD A BULLET ABOUT WHAT THIS IS DOING BEHIND THE SCENES
The version is in under the `IMAGE` tag: `1.21.1`.

Next, refer to the following resources for installing kubectl:

- [Linux](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/)
- [Mac](https://kubernetes.io/docs/tasks/tools/install-kubectl-macos/)
- [Windows](https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/)

Here's an example of how to download kubectl v1.21.1 on a Unix-based environment:

```bash
$ curl -LO "https://storage.googleapis.com/kubernetes-release/release/v1.21.1/bin/darwin/amd64/kubectl"
$ chmod +x ./kubectl
$ sudo mv ./kubectl /usr/local/bin/kubectl
```

Check the version:

```bash
$ kubectl version --client

Client Version: version.Info{
    Major:"1",
    Minor:"21",
    GitVersion:"v1.21.0",
    GitCommit:"cb303e613a121a29364f75cc67d3d580833a7479",
    GitTreeState:"clean",
    BuildDate:"2021-04-08T21:15:16Z",
    GoVersion:"go1.16.3",
    Compiler:"gc",
    Platform:"darwin/amd64"
}
```

Finally, to ensure the cluster is up and running, run:

```bash
$ kubectl cluster-info --context kind-cluster1

Kubernetes control plane is running at https://127.0.0.1:61107
CoreDNS is running at https://127.0.0.1:61107/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
```

## Environment Setup

Let's start by creating a Python virtual environment on our local machine.

> We'll be using Python's [venv](https://docs.python.org/3/library/venv.html) module along with [pip](https://pip.pypa.io/en/stable/), but feel free to swap them out for [Poetry](https://python-poetry.org/) or [Pipenv](https://github.com/pypa/pipenv) if you're more comfortable using one of those dependency management tools instead.

> For more on pip and venv vs Poetry vs Pipenv, review [Modern Python Environments](/blog/python-environments/).

Open a new terminal window and enter the following commands:

```bash
$ mkdir -p gitops-flask-kubernetes
$ cd gitops-flask-kubernetes
$ python3.9 -m venv env
$ source env/bin/activate

(env)$ python -V
Python 3.9.5
```

Next, let's create a *requirements.txt* file at the project root to define our Python dependencies:

```bash
# gitops-flask-kubernetes/requirements.txt

Flask==2.0.1
kubernetes==17.17.0
pytest==6.2.4
```

Run the following command to install them:

```sh
(env)$ pip install -r requirements.txt
```

## Test-driven Development

Now that our Kubernetes cluster is up, let's run some basic smoke tests using [pytest](https://docs.pytest.org/en/stable/).

### What's a smoke test?

A [smoke test](https://softwaretestingfundamentals.com/smoke-testing) checks that some basic foundations are up before we proceed to test our application. For example, if we can create a Namespace in our Kubernetes cluster and deploy our application, we have proven that the underlying infrastructure is up and working. That way we can focus on doing end-to-end testing on our application running on a Kubernetes cluster.

### Smoke Test

We'll be making use of the Kubernetes API server to see if we can create a [Namespace](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/). Let's write up our first test.

First, we need to define a YAML definition for our namespace as follows:

```yaml
# gitops-flask-kubernetes/namespace.yaml

apiVersion: v1
kind: Namespace
metadata:
  name: test-namespace
```

We defined the "core" v1 API to define our Namespace.

Let's create a "tests" directory and proceed to define our tests:

```bash
$ mkdir tests
```

Test:

```python
# gitops-flask-kubernetes/tests/test_smoke.py

import yaml
from kubernetes import client, config

config.load_kube_config(context="kind-cluster1")


class TestSmoke:
    def setup_class(self):
        self.core_v1 = client.CoreV1Api()

    def test_create_namespace(self):
        with open("namespace.yaml") as f:
            namespace = yaml.safe_load(f)
        response = self.core_v1.create_namespace(body=namespace)
        result = self.core_v1.read_namespace(name="test-namespace")
        assert "test-namespace" == result.metadata.name
```

What's happening?

1. We first imported the relevant libraries and defined a kube config and context. This config and context were generated when we created our `kind` cluster.
1. We then defined the core v1 client and set it as a class attribute. This way we use the same client in multiple tests rather than having to define it every time.
1. We then defined the `test_create_namespace` method which makes use of our `core_v1` attribute.
1. With our client ready, we loaded the YAML that we defined and created our Namespace before running an assert.

Run the smoke test (note that pytest by default will look for files starting with `test_` in the "tests" directory):

```bash
(env)$ pytest

=============================== test session starts ===============================
platform darwin -- Python 3.9.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1
rootdir: /Users/michael/repos/testdriven/gitops-flask-kubernetes
collected 1 item

test_smoke.py .                                                             [100%]

================================ 1 passed in 0.92s ================================
```

Our test passed!

Verify that our Namespace exists using `kubectl`:

```bash
(env)$ kubectl get namespaces
```

You should see the `test-namespace` Namespace:

```bash
NAME                 STATUS   AGE
default              Active   44m
kube-node-lease      Active   44m
kube-public          Active   44m
kube-system          Active   44m
local-path-storage   Active   44m
test-namespace       Active   2m35s
```

We have verified that our Namespace exists.

Let's run our test again:

```bash
(env)$ pytest
```

It should fail:

```bash
        if not 200 <= r.status <= 299:
>           raise ApiException(http_resp=r)
E           kubernetes.client.exceptions.ApiException: (409)
E           Reason: Conflict
E           HTTP response headers: HTTPHeaderDict({'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'X-Kubernetes-Pf-Flowschema-Uid': 'aca37ad3-8408-4b16-8610-dd372652dbc9', 'X-Kubernetes-Pf-Prioritylevel-Uid': '5f3c0cb4-a877-4785-918b-5b15d36147f1', 'Date': 'Mon, 07 Jun 2021 02:58:09 GMT', 'Content-Length': '218'})
E           HTTP response body: {"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"namespaces \"test-namespace\" already exists","reason":"AlreadyExists","details":{"name":"test-namespace","kind":"namespaces"},"code":409}

env/lib/python3.9/site-packages/kubernetes/client/rest.py:233: ApiException
```

The test fails now since the Kubernetes API server returns a 409 with the following error message:

```bash
namespaces "test-namespace" already exists
```

This is expected since the Namespace, well, already exists. To fix this, add a tear down step in the tests to delete the Namespace:

```python
# gitops-flask-kubernetes/tests/test_smoke.py

import yaml
from kubernetes import client, config

config.load_kube_config(context="kind-cluster1")


class TestSmoke:
    def setup_class(self):
        self.core_v1 = client.CoreV1Api()

    def test_create_namespace(self):
        with open("namespace.yaml") as f:
            namespace = yaml.safe_load(f)
        response = self.core_v1.create_namespace(body=namespace)
        result = self.core_v1.read_namespace(name="test-namespace")
        assert "test-namespace" == result.metadata.name

    # new
    def teardown_class(self):
        self.core_v1.delete_namespace(name="test-namespace")
```

The only change above is that we're now deleting the Namespace in the `teardown_class` method.

Before testing, manually delete the Namespace using `kubectl`:

```bash
(env)$ kubectl delete ns test-namespace --context kind-cluster1

namespace "test-namespace" deleted
```

Try running the tests again:

```bash
(env)$ pytest
```

It should pass.

Try running it a few more times. You should see it fail randomly with the following error:

```bash
>           raise ApiException(http_resp=r)
E           kubernetes.client.exceptions.ApiException: (409)
E           Reason: Conflict
E           HTTP response headers: HTTPHeaderDict({'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'X-Kubernetes-Pf-Flowschema-Uid': 'aca37ad3-8408-4b16-8610-dd372652dbc9', 'X-Kubernetes-Pf-Prioritylevel-Uid': '5f3c0cb4-a877-4785-918b-5b15d36147f1', 'Date': 'Mon, 07 Jun 2021 03:04:23 GMT', 'Content-Length': '243'})
E           HTTP response body: {"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"object is being deleted: namespaces \"test-namespace\" already exists","reason":"AlreadyExists","details":{"name":"test-namespace","kind":"namespaces"},"code":409}

env/lib/python3.9/site-packages/kubernetes/client/rest.py:233: ApiException
```

Why is this happening? Take note of the error message:

```bash
object is being deleted: namespaces "test-namespace" already exists
```

The above failure happened because we didn't wait long enough between the test runs. It can take a second or two for Kubernetes to delete all of the resources associated with a Namespace.

Wait a few seconds before running the tests again. They should now pass.

```bash
(env)$ pytest

=============================== test session starts ===============================
platform darwin -- Python 3.9.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1
rootdir: /Users/michael/repos/testdriven/gitops-flask-kubernetes
collected 1 item

test_smoke.py .                                                             [100%]

================================ 1 passed in 0.42s ================================
```

Rather than forcing the end user to wait a few seconds between test runs, you can create a Namespace with a name which includes random numbers or letters. We won't be covering this in this course, so try this on your own if you'd like. Instead, we'll refactor the tests in an upcoming chapter to create a Deployment. This will prevent having to pause a few seconds between test runs.

## Summary

Let's wrap up here. In this chapter, we set up a local kind cluster and created a Namespace. We also discovered that deleting Kubernetes resources can take a few seconds, so you'll need to pause for a few seconds between test runs or create a uniquely named Namespace to avoid clashing.

Your project structure should now look like this:

```bash
├── namespace.yaml
├── requirements.txt
└── tests
    └── test_smoke.py
```
