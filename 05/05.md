# Setting up GitOps

In this chapter, we'll deploy our Flask application and all of its components using GitOps. Before we begin lets explore the "state of deploying" in the Kubernetes world.

## Deploying Kubernetes Applications

One way to represent a Kubernetes resource is to write it in YAML or JSON format. Over the years a few solutions have come to help deploy complex applications in Kubernetes. Let's explore the pros and cons of the different tools available to us.

| Library     | Supports Templating | Tracks Releases    | Syncs with Git |
| ----------- | ------------------- | ------------------ | -------------- |
| Kubectl     | &cross;             | &cross;            | &cross;        |
| Kustomise   | &cross;             | &cross;            | &cross;        |
| Helm        | &check;             | &check;            | &cross;        |
| Flux        | &cross;             | &check;            | &check;        |

### Kubectl

Throughout this course, we've been using the [kubectl](https://kubernetes.io/docs/reference/kubectl/overview/) CLI tool to interact with the Kubernetes API server. It's possible to simply write up your resource manifests and run `kubectl apply` to deploy your resources. Whilst this way is powerful, it's bare bones. There's no way to parameterize variables or even have variables, one can use [consul-template](https://github.com/hashicorp/consul-template) or [sed](https://www.gnu.org/software/sed/manual/sed.html) to replace variables but that's a manual process and requires effort on the developer side. It's also not possible to version or keep track of your releases without manually adding some glue. Rollback is manual and pretty much everything has to be done manually. Whilst this will work for experimenting, for production based workloads this is not an acceptable solution.

### Kustomize

[Kustomize](https://kustomize.io/) is a native way to deploy Kubernetes applications. It's part of kubectl. One can simply run `kubectl apply -k` and tap into Kustomize. Kustomise doesn't make use of templates. Instead, it uses a "base" manifest that patches existing YAML manifests to make each file unique. While it helps to cut down repetition in the manifest definitions, it doesn't have the ability to track the application and perform rollbacks. That functionality is left to the discretion of the developer. Kustomise is a production-ready solution that's able to cater to complex application needs such as multiple clusters and batch jobs.

### Helm

[Helm](https://helm.sh/) is a package manager for Kubernetes. It enables the user to write up a "chart", which contains metadata about the application and the chart itself. A chart is a collection of Kubernetes resources and metadata about them. Engineers can use Helm to template Kubernetes resources, making it a powerful solution for deploying to multiple clusters, for example. Once a chart is deployed, Helm stores the state of the release -- a deployment of a chart -- in a ConfigMap. This makes it easy to track which version is running on the cluster via the `helm ls` command. It's possible to push updates to the Helm release by upgrading as well. Rollback is available via the `helm rollback` command. Helm is not a silver bullet as it is not suitable for all resources such as batch jobs. For production workloads, Helm is a popular choice due to its array of features.

### Flux

![from https://fluxcd.io](flux.png)

[Flux](https://fluxcd.io/) is a GitOps operator developed by [Weaveworks](https://www.weave.works/). The open source version implements GitOps by syncing the resources in a git repository down to the kubernetes cluster and comes with the `fluxctl` CLI. Flux is production=ready and used by [these organizations](https://fluxcd.io/adopters/). We'll be implementing Flux in our Kubernetes cluster to deploy our Flask application in this chapter. This course uses Flux v2. The previous generation of Flux (v1), which works the same way, but is an older iteration, will be covered in later chapters. The major difference between v1 and v2 is that v2 is more of a Kubernetes native approach rather than an application that runs on Kubernetes. More Kubernetes features such as [Custom Resource Definitions](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#customresourcedefinitions) (CRDs) and Kustomize are used to make the whole GitOps pipeline more flexible and extensible.

## Deploying Flux

Start by [installing](https://fluxcd.io/docs/installation/) Flux.

Verify the version:

```bash
$ flux --version
flux version 0.16.1
```

We created a kind cluster in the previous chapters. If it's still up and running, it can be reused otherwise a new one can be created. To create a new cluster, run the following:

```bash
$ kind create cluster --name cluster1

Creating cluster "cluster1" ...
 ‚úì Ensuring node image (kindest/node:v1.19.1) üñº
 ‚úì Preparing nodes üì¶
 ‚úì Writing configuration üìú
 ‚úì Starting control-plane üïπÔ∏è
 ‚úì Installing CNI üîå
 ‚úì Installing StorageClass üíæ
Set kubectl context to "kind-cluster1"
You can now use your cluster with:

kubectl cluster-info --context kind-cluster1
```

Before we begin, we need to generate a GitHub [personal access token](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) in order to create a private repository. Create a new token with `repo` access.

Let's install Flux on the kind cluster:

```bash
$ export GITHUB_USER=<your-username>
$ export GITHUB_TOKEN=<your-token-from-https://github.com/settings/tokens>

$ flux bootstrap github \
  --owner=$GITHUB_USER \
  --repository=fleet-infra \
  --branch=main \
  --path=./clusters/kind/cluster1 \
  --personal
```

You should see something similar to:

```bash
‚ñ∫ connecting to github.com
‚úî repository created
‚úî repository cloned
‚úö generating manifests
‚úî components manifests pushed
‚ñ∫ installing components in flux-system namespace
namespace/flux-system created
customresourcedefinition.apiextensions.k8s.io/alerts.notification.toolkit.fluxcd.io created
customresourcedefinition.apiextensions.k8s.io/buckets.source.toolkit.fluxcd.io created
customresourcedefinition.apiextensions.k8s.io/gitrepositories.source.toolkit.fluxcd.io created
customresourcedefinition.apiextensions.k8s.io/helmcharts.source.toolkit.fluxcd.io created
customresourcedefinition.apiextensions.k8s.io/helmreleases.helm.toolkit.fluxcd.io created
customresourcedefinition.apiextensions.k8s.io/helmrepositories.source.toolkit.fluxcd.io created
customresourcedefinition.apiextensions.k8s.io/kustomizations.kustomize.toolkit.fluxcd.io created
customresourcedefinition.apiextensions.k8s.io/providers.notification.toolkit.fluxcd.io created
customresourcedefinition.apiextensions.k8s.io/receivers.notification.toolkit.fluxcd.io created
role.rbac.authorization.k8s.io/crd-controller-flux-system created
rolebinding.rbac.authorization.k8s.io/crd-controller-flux-system created
clusterrolebinding.rbac.authorization.k8s.io/cluster-reconciler-flux-system created
service/notification-controller created
service/source-controller created
service/webhook-receiver created
deployment.apps/helm-controller created
deployment.apps/kustomize-controller created
deployment.apps/notification-controller created
deployment.apps/source-controller created
networkpolicy.networking.k8s.io/allow-scraping created
networkpolicy.networking.k8s.io/allow-webhooks created
networkpolicy.networking.k8s.io/deny-ingress created
Waiting for deployment "source-controller" rollout to finish: 0 of 1 updated replicas are available...
deployment "source-controller" successfully rolled out
deployment "kustomize-controller" successfully rolled out
deployment "helm-controller" successfully rolled out
deployment "notification-controller" successfully rolled out
‚úî install completed
‚ñ∫ configuring deploy key
‚úî deploy key configured
‚ñ∫ generating sync manifests
‚úî sync manifests pushed
‚ñ∫ applying sync manifests
‚óé waiting for cluster sync
‚úî bootstrap finished
```

> The command we ran was specific for GitHub. GitLab can be used as well. Create a token, set the environment variable for `GITLAB_TOKEN`, and then run `flux bootstrap gitlab`.

This created a private repository called fleet-infra, which stores the Flux [Manifests](https://kubernetes.io/docs/reference/glossary/?all=true#term-manifest):

```
https://github.com/your_username/fleet-infra/tree/main/clusters/kind/cluster1/flux-system
```

This also installed the `flux-system` Namespace and number of CRDs, including the `helm-controller`.

To see exactly what was created, run:

```bash
$ kubectl get pods -n flux-system

NAME                                      READY   STATUS    RESTARTS   AGE
helm-controller-86d6475c46-b8hdf          1/1     Running   0          2m48s
kustomize-controller-689f679f79-kqbxn     1/1     Running   0          2m48s
notification-controller-b8fbd5997-p6fsb   1/1     Running   0          2m48s
source-controller-5bb54b4c66-95pld        1/1     Running   0          2m48s
```

Let's list the Git Repositories that Flux is keeping in sync with our Kind cluster.

```bash
$ kubectl get gitrepository -n flux-system

NAME          URL                                          READY   STATUS                                                            AGE
flux-system   ssh://git@github.com/paktek123/fleet-infra   True    Fetched revision: main/fe52e00bcaf3f645252f743da1720c2921d4ebd8   3m48s
```
We can see `fleet-infra` repository which holds the manifests for our Flux installation. One feature to note is that the `flux bootstrap` command is idempotent and can be used to upgrade the version of Flux running.

## Deploying a Sample Application

Flux v2 introduced the concept of multiple git repositories, which was a major limitation of Flux v1.

Let's create a new git repository with a sample application developed by the maintainers of Flux:

```bash
$ flux create source git podinfo \
  --url=https://github.com/stefanprodan/podinfo \
  --branch=master \
  --interval=30s

‚úö generating GitRepository source
‚ñ∫ applying GitRepository source
‚úî GitRepository source created
‚óé waiting for GitRepository source reconciliation
‚úî GitRepository source reconciliation completed
‚úî fetched revision: master/855f7724be13f6146f61a893851522837ad5b634
```

Let's see below if Flux is tracking our sample `podinfo` Git Repository.

```bash
$ kubectl get gitrepository -n flux-system

NAME          URL                                            READY   STATUS                                                              AGE
flux-system   ssh://git@github.com/paktek123/fleet-infra     True    Fetched revision: main/fe52e00bcaf3f645252f743da1720c2921d4ebd8     6m27s
podinfo       https://github.com/stefanprodan/podinfo        True    Fetched revision: master/855f7724be13f6146f61a893851522837ad5b634   30s
```

This applied the following manifest:

```yaml
apiVersion: source.toolkit.fluxcd.io/v1beta1
kind: GitRepository
metadata:
  name: podinfo
  namespace: flux-system
spec:
  interval: 30s
  ref:
    branch: master
  url: https://github.com/stefanprodan/podinfo
```


> Take note that adding the git repository does not `kubectl apply` all the YAML files as it did with Flux v1. Instead we have to use a new API called [Kustomization](https://fluxcd.io/docs/components/kustomize/kustomization/). Since Kustomize is now part of kubectl, Flux v2 capitalizes on this fact and uses it as a default.

Let's deploy our tutorial application.

```bash
$ flux create kustomization podinfo \
  --source=podinfo \
  --path="./kustomize" \
  --prune=true \
  --validation=client \
  --interval=5m

‚úö generating Kustomization
‚ñ∫ applying Kustomization
‚úî Kustomization created
‚óé waiting for Kustomization reconciliation
‚úî Kustomization podinfo is ready
‚úî applied revision master/855f7724be13f6146f61a893851522837ad5b634
```

The above will generate the following manifest and apply it to our cluster:

```yaml
apiVersion: kustomize.toolkit.fluxcd.io/v1beta1
kind: Kustomization
metadata:
  name: podinfo
  namespace: flux-system
spec:
  interval: 5m0s
  path: ./kustomize
  prune: true
  sourceRef:
    kind: GitRepository
    name: podinfo
  validation: client
```

In the above we reference the *./kustomize* directory in the podinfo repository where *kustomization.yaml* is. To deploy via the Kustomize Controller we always reference the directory where the `kustomization.yaml` resides. We will explore this in more depth in further chapters. Let's have a look what the *kustomization.yaml* file looks like:

```yaml
# podinfo/kustomize/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - hpa.yaml
  - deployment.yaml
  - service.yaml
```

We defined the resources that we want deployed and Flux v2 in the background will run a `kubectl apply -k` to apply the manifest. Let's verify that our sample application is running:

```bash
$ kubectl get pods
NAME                      READY   STATUS    RESTARTS   AGE
podinfo-699d86644-85hjq   1/1     Running   0          3m56s
podinfo-699d86644-fnb5s   1/1     Running   0          3m40s

$ kubectl get hpa
NAME      REFERENCE            TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
podinfo   Deployment/podinfo   <unknown>/99%   2         4         2          5m1s

$ kubectl get svc
NAME         TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)             AGE
kubernetes   ClusterIP   10.96.0.1     <none>        443/TCP             30m
podinfo      ClusterIP   10.96.59.77   <none>        9898/TCP,9999/TCP   5m24s

$ kubectl get kustomizations -n flux-system
NAME          READY   STATUS                                                              AGE
flux-system   True    Applied revision: main/fe52e00bcaf3f645252f743da1720c2921d4ebd8     30m
podinfo       True    Applied revision: master/855f7724be13f6146f61a893851522837ad5b634   7m11s
```

We can see the Deployment, Pods, HPA (Horizontal Pod Autoscaler) and Service has been created and applied.

## Flux Internals

Flux has many components that play a part on how a deployment works. In this section, we'll explore each one of them to understand how they work.

If we list the running Pods in the `flux-system` Namespace we can see we have four controllers running:

```bash
$ kubectl get pods -n flux-system

NAME                                       READY   STATUS    RESTARTS   AGE
helm-controller-845fdc89d4-mkdbw           1/1     Running   0          23m
kustomize-controller-7f589bfbd5-sfmqz      1/1     Running   0          23m
notification-controller-5f7ff9d469-x92zq   1/1     Running   0          23m
source-controller-6b4d8df7f7-bgwqp         1/1     Running   0          23m
```

### Source Controller

![from https://toolkit.fluxcd.io/components/source/controller/](source-controller.png)

The [Source Controller](https://fluxcd.io/docs/components/source/)'s purpose is to download the Kubernetes manifests or Helm Charts that need to be deployed to the cluster. Multiple sources are supported:

1. Git Repository
1. Helm Repository
1. S3 Bucket (AWS, Google Cloud Storage, MinIO)


in the above example we used a [GitRepository](https://fluxcd.io/docs/components/source/gitrepositories/) CRD to point to the sample Git repository set up by the Flux maintainers.

A [Helm Repository](https://fluxcd.io/docs/components/source/helmrepositories/) is used to store Helm Charts. It's possible to point a server that hosts Helm Charts and reference them as a [HelmChart CRD](https://fluxcd.io/docs/components/source/helmcharts/). We'll touch on this in more detail in chapter 8.

The [Bucket](https://fluxcd.io/docs/components/source/buckets/) CRD is used to represent an S3 bucket which can host Kubernetes manifests. An S3 bucket typically represents a file-system style structure where prefixes (or keys) define paths to objects. When we define a Bucket CRD, in the background, the source controller will download the objects in the S3 bucket which can be referenced in a `Kustomization` CRD or a `HelmChart` CRD. We'll dive into further detail in chapter 6 for both the Bucket and GitRepository CRDs.

Let's have a look at what the source controllers logs say:

```bash
$ kubectl logs source-controller-6b4d8df7f7-bgwqp -n flux-system

{"level":"info","ts":"2021-03-24T15:19:53.187Z","logger":"controller.gitrepository","msg":"Reconciliation finished in 421.7017ms, next run in 30s","reconciler group":"source.toolkit.fluxcd.io","reconciler kind":"GitRepository","name":"podinfo","namespace":"flux-system"}
```

As we can see, the GitRepository is constantly "reconciling" the state, meaning that it checks if the Git SHA is matching. If it changes, then a new check out is done by the source controller to ensure our artifacts are matching what's provided in the CRD. If there are any issues then checking the logs can give us an insight into what the issue might be.

### Kustomize Controller

![from https://toolkit.fluxcd.io/components/kustomize/controller/](kustomize-controller.png)

The [Kustomize Controller](https://fluxcd.io/docs/components/kustomize/) is a Kubernetes operator used to deploy Kubernetes workloads via Kustomize. When Flux v1 came out, many users quickly began to leverage Kustomize to reduce the repetition in their Kubernetes manifests across environments. The Kustomize controller now supports this natively making Flux v2 much more powerful. To setup continuous delivery, a Kustomization CRD can be set up to trigger the sync between the git repository and the Kubernetes cluster.

Let's look at the logs of the controller to understand what's happening (pretty printed via [jq](https://stedolan.github.io/jq/):

```bash
$ kubectl logs kustomize-controller-7f589bfbd5-sfmqz -n flux-system | jq

{
  "level": "info",
  "ts": "2021-03-22T10:28:21.162Z",
  "logger": "controller.kustomization",
  "msg": "Kustomization applied in 502.2033ms",
  "reconciler group": "kustomize.toolkit.fluxcd.io",
  "reconciler kind": "Kustomization",
  "name": "flux-system",
  "namespace": "flux-system",
  "output": {
    "clusterrole.rbac.authorization.k8s.io/crd-controller-flux-system": "unchanged",
    "clusterrolebinding.rbac.authorization.k8s.io/cluster-reconciler-flux-system": "unchanged",
    "clusterrolebinding.rbac.authorization.k8s.io/crd-controller-flux-system": "unchanged",
    "customresourcedefinition.apiextensions.k8s.io/alerts.notification.toolkit.fluxcd.io": "configured",
    "customresourcedefinition.apiextensions.k8s.io/buckets.source.toolkit.fluxcd.io": "configured",
    "customresourcedefinition.apiextensions.k8s.io/gitrepositories.source.toolkit.fluxcd.io": "configured",
    "customresourcedefinition.apiextensions.k8s.io/helmcharts.source.toolkit.fluxcd.io": "configured",
    "customresourcedefinition.apiextensions.k8s.io/helmreleases.helm.toolkit.fluxcd.io": "configured",
    "customresourcedefinition.apiextensions.k8s.io/helmrepositories.source.toolkit.fluxcd.io": "configured",
    "customresourcedefinition.apiextensions.k8s.io/kustomizations.kustomize.toolkit.fluxcd.io": "configured",
    "customresourcedefinition.apiextensions.k8s.io/providers.notification.toolkit.fluxcd.io": "configured",
    "customresourcedefinition.apiextensions.k8s.io/receivers.notification.toolkit.fluxcd.io": "configured",
    "deployment.apps/helm-controller": "configured",
    "deployment.apps/kustomize-controller": "configured",
    "deployment.apps/notification-controller": "configured",
    "deployment.apps/source-controller": "configured",
    "gitrepository.source.toolkit.fluxcd.io/flux-system": "unchanged",
    "kustomization.kustomize.toolkit.fluxcd.io/flux-system": "unchanged",
    "namespace/flux-system": "unchanged",
    "networkpolicy.networking.k8s.io/allow-scraping": "unchanged",
    "networkpolicy.networking.k8s.io/allow-webhooks": "unchanged",
    "networkpolicy.networking.k8s.io/deny-ingress": "unchanged",
    "service/notification-controller": "unchanged",
    "service/source-controller": "unchanged",
    "service/webhook-receiver": "unchanged",
    "serviceaccount/helm-controller": "unchanged",
    "serviceaccount/kustomize-controller": "unchanged",
    "serviceaccount/notification-controller": "unchanged",
    "serviceaccount/source-controller": "unchanged"
  }
}
{
  "level": "info",
  "ts": "2021-03-22T10:32:44.366Z",
  "logger": "controller.kustomization",
  "msg": "Reconciliation finished in 890.3928ms, next run in 5m0s",
  "reconciler group": "kustomize.toolkit.fluxcd.io",
  "reconciler kind": "Kustomization",
  "name": "podinfo",
  "namespace": "flux-system",
  "revision": "master/ef98a040c89180a4f39c0ab01dac47e6c3fced08"
}
{
  "level": "info",
  "ts": "2021-03-22T10:37:44.899Z",
  "logger": "controller.kustomization",
  "msg": "Kustomization applied in 308.7763ms",
  "reconciler group": "kustomize.toolkit.fluxcd.io",
  "reconciler kind": "Kustomization",
  "name": "podinfo",
  "namespace": "flux-system",
  "output": {
    "deployment.apps/podinfo": "configured",
    "horizontalpodautoscaler.autoscaling/podinfo": "unchanged",
    "service/podinfo": "unchanged"
  }
}
```

In the output, we can see that every five minutes the Kustomize controller runs a sync loop where it does a `kubectl apply -k` and returns the output in the logs. The controller logs are also a great place to find any errors if there are any during the apply. So if I delete any of my YAML files will it also delete my resources? In this case when we defined our Kustomization CRD we passed `spec.prune` to `true` -- so, yes if we delete something from the git repository our change will reflect on the cluster.

### Helm Controller

![from https://toolkit.fluxcd.io/components/helm/controller/](helm-controller.png)

The [Helm Controller](https://fluxcd.io/docs/components/helm/) is used to manage the life cycle of Helm Charts deployed via Flux. Similar to how Kustomizations work, the Helm controller watches for [HelmRelease](https://fluxcd.io/docs/components/helm/helmreleases/) CRDs and deploys them to a Kubernetes cluster. We'll touch on this in chapter 8 with practical examples.

### Notification Controller

![from https://toolkit.fluxcd.io/components/notification/controller/](notification-controller.png)

The [Notification Controller](https://fluxcd.io/docs/components/notification/) handles events coming from version control or external systems and notifies the other controllers (Source, Kustomize, Helm). This helps ensure that all events are coordinated and all components are up-to-date with all the changes that are going on. The controller can also be configured to send Slack, Teams, or Discord notifications of deploy events. This is an internal component. We won't be interfacing with it in this course.

## Summary

Let's wrap up here. In this chapter, we explored deployment options for Kubernetes clusters and installed Flux v2 on our local cluster. We then forked a sample repository provided by the Flux maintainers and synced it with our local cluster. Then we went into detail on the individual controllers and what role they play in the Flux ecosystem.

## Further reading

- Flux: https://toolkit.fluxcd.io/get-started/
- Horizontal Pod Autoscaler: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
- Flux Garbage Collection: https://toolkit.fluxcd.io/components/kustomize/kustomization/#garbage-collection
